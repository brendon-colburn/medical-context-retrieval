{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Medical RAG System - Admin Panel\n\n## üîß Administrative Interface\n\nUse this interface to manage the medical knowledge base, rebuild indexes, and perform system maintenance.\n\n**‚ö†Ô∏è Access Control**: This panel should only be accessible to administrators.\n\n---\n\n## üéì Educational Mode Toggle\n\nThis notebook supports **two learning paths** for understanding RAG systems:\n\n### üìö Local Mode (FAISS + JSON)\n**Best for:** Learning RAG fundamentals, offline development, rapid experimentation\n\n**You'll learn:**\n- How to chunk documents with semantic boundaries\n- How embedding generation works with Azure OpenAI\n- How FAISS vector indexes are built and queried\n- How to cache and persist data locally\n\n**Storage:** Everything saved in local `cache/` directory\n\n### ‚òÅÔ∏è Azure Mode (Cosmos DB + Azure AI Search)\n**Best for:** Understanding production RAG systems, cloud architecture, scalability\n\n**You'll learn:**\n- How to store documents in Azure Cosmos DB (NoSQL database)\n- How to populate Azure AI Search with embeddings\n- How HNSW vector search works in the cloud\n- How to manage production-scale RAG infrastructure\n\n**Storage:** Documents in Cosmos DB, vectors in Azure AI Search\n\n---\n\n**Current Mode:** The system will detect `STORAGE_MODE` from your `.env` file and show you the appropriate workflow below."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# System initialization\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport ipywidgets as widgets\nfrom IPython.display import display, HTML, clear_output\nimport os\nfrom pathlib import Path\nimport json\nfrom datetime import datetime\n\nfrom rag import config\n\n# Display current mode prominently\nmode_color = \"#0066cc\" if config.STORAGE_MODE == \"local\" else \"#28a745\"\nmode_icon = \"üìö\" if config.STORAGE_MODE == \"local\" else \"‚òÅÔ∏è\"\nmode_name = \"Local (FAISS + JSON)\" if config.STORAGE_MODE == \"local\" else \"Azure (Cosmos DB + AI Search)\"\n\ndisplay(HTML(f'''\n<div style=\"background-color: {mode_color}; color: white; padding: 15px; border-radius: 8px; margin-bottom: 20px;\">\n    <h2 style=\"margin: 0;\">{mode_icon} Current Mode: {mode_name}</h2>\n    <p style=\"margin: 5px 0 0 0; opacity: 0.9;\">\n        To change modes, update <code style=\"background-color: rgba(255,255,255,0.2); padding: 2px 6px; border-radius: 3px;\">STORAGE_MODE</code> in your <code style=\"background-color: rgba(255,255,255,0.2); padding: 2px 6px; border-radius: 3px;\">.env</code> file and restart this notebook.\n    </p>\n</div>\n'''))\n\n# Import mode-specific modules\nif config.STORAGE_MODE == \"azure\":\n    from rag import azure_cosmos, azure_search\n    print(\"‚úÖ Azure modules loaded (Cosmos DB + AI Search)\")\nelse:\n    from rag.cache import save_chunks, save_faiss_index, save_metadata, load_chunks, load_faiss_index\n    print(\"‚úÖ Local cache modules loaded (FAISS + JSON)\")\n\nprint(f\"üìÅ Data directory: {config.DATA_DIR}\")\nif config.STORAGE_MODE == \"local\":\n    print(f\"üì¶ Cache directory: {config.CACHE_DIR}\")\nelse:\n    print(f\"‚òÅÔ∏è  Cosmos DB: {config.COSMOS_DB_NAME}\")\n    print(f\"üîç Azure Search Index: {config.AZURE_SEARCH_INDEX_NAME}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä System Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Status display\nstatus_output = widgets.Output()\n\ndef refresh_status(button=None):\n    with status_output:\n        clear_output()\n        \n        if config.STORAGE_MODE == \"azure\":\n            # Azure mode status\n            try:\n                from rag import azure_cosmos, azure_search\n                \n                # Get counts from Azure services\n                doc_count = 0\n                chunk_count = 0\n                search_count = 0\n                \n                try:\n                    cosmos_stats = azure_cosmos.get_stats()\n                    doc_count = cosmos_stats.get('document_count', 0)\n                    chunk_count = cosmos_stats.get('chunk_count', 0)\n                except Exception as e:\n                    display(HTML(f'<p style=\"color: #dc3545;\">‚ö†Ô∏è Could not connect to Cosmos DB: {str(e)}</p>'))\n                \n                try:\n                    search_count = azure_search.get_document_count()\n                except Exception as e:\n                    display(HTML(f'<p style=\"color: #dc3545;\">‚ö†Ô∏è Could not connect to Azure Search: {str(e)}</p>'))\n                \n                # Build status HTML\n                status_html = '<div style=\"background-color: #f0fff4; padding: 20px; border-radius: 10px; border-left: 5px solid #28a745;\">'\n                status_html += '<h3 style=\"margin-top: 0; color: #28a745;\">‚òÅÔ∏è Azure Mode Status</h3>'\n                status_html += '<h4 style=\"color: #666;\">Azure Cosmos DB (Document Storage)</h4>'\n                status_html += f'<p><strong>Documents:</strong> {doc_count:,}</p>'\n                status_html += f'<p><strong>Chunks:</strong> {chunk_count:,}</p>'\n                status_html += '<h4 style=\"color: #666; margin-top: 15px;\">Azure AI Search (Vector Index)</h4>'\n                status_html += f'<p><strong>Indexed Chunks:</strong> {search_count:,}</p>'\n                \n                if chunk_count > 0 and search_count == chunk_count:\n                    status_html += f'<p style=\"color: #28a745; font-weight: bold; margin-top: 15px;\">‚úÖ System is fully synchronized and operational!</p>'\n                elif chunk_count > 0 and search_count == 0:\n                    status_html += f'<p style=\"color: #ffc107; font-weight: bold; margin-top: 15px;\">‚ö†Ô∏è Chunks exist in Cosmos DB but not indexed in Azure Search. Run \"Process Documents\" to populate the index.</p>'\n                elif chunk_count > 0 and search_count != chunk_count:\n                    status_html += f'<p style=\"color: #ffc107; font-weight: bold; margin-top: 15px;\">‚ö†Ô∏è Mismatch: {chunk_count} chunks in Cosmos DB but {search_count} in Azure Search. Consider rebuilding.</p>'\n                else:\n                    status_html += f'<p style=\"color: #dc3545; font-weight: bold; margin-top: 15px;\">‚ùå No data found. Run \"Process Documents\" to populate Azure services.</p>'\n                \n                status_html += '</div>'\n                display(HTML(status_html))\n                \n            except Exception as e:\n                display(HTML(f'<p style=\"color: #dc3545;\">Error checking Azure status: {str(e)}</p>'))\n        \n        else:\n            # Local mode status\n            from rag.cache import load_chunks, load_faiss_index\n            \n            # Check for existing data\n            chunks = load_chunks()\n            index = load_faiss_index()\n            \n            # Count PDFs\n            pdf_count = len(list(config.PDF_DIR.glob('*.pdf')))\n            \n            # Check cache files\n            cache_files = {\n                'chunks.pkl': (config.CACHE_DIR / 'chunks.pkl').exists(),\n                'faiss_index.bin': (config.CACHE_DIR / 'faiss_index.bin').exists(),\n                'metadata.json': (config.CACHE_DIR / 'chunk_metadata.json').exists()\n            }\n            \n            # Build status HTML\n            status_html = '<div style=\"background-color: #f0f9ff; padding: 20px; border-radius: 10px; border-left: 5px solid #0066cc;\">'\n            status_html += '<h3 style=\"margin-top: 0; color: #0066cc;\">üìö Local Mode Status</h3>'\n            status_html += f'<p><strong>PDF Documents:</strong> {pdf_count}</p>'\n            status_html += f'<p><strong>Processed Chunks:</strong> {len(chunks) if chunks else 0}</p>'\n            status_html += f'<p><strong>FAISS Index:</strong> {\"‚úÖ Built\" if index else \"‚ùå Not found\"}</p>'\n            status_html += '<p><strong>Cache Files:</strong></p><ul>'\n            for file, exists in cache_files.items():\n                icon = '‚úÖ' if exists else '‚ùå'\n                status_html += f'<li>{icon} {file}</li>'\n            status_html += '</ul>'\n            \n            if chunks:\n                status_html += f'<p style=\"color: #28a745; font-weight: bold; margin-top: 15px;\">‚úÖ System is operational and ready to serve queries.</p>'\n            else:\n                status_html += f'<p style=\"color: #dc3545; font-weight: bold; margin-top: 15px;\">‚ùå System needs initialization. Please process documents below.</p>'\n            \n            status_html += '</div>'\n            display(HTML(status_html))\n\nrefresh_button = widgets.Button(\n    description='üîÑ Refresh Status',\n    button_style='info',\n    layout=widgets.Layout(width='200px', margin='10px 0')\n)\nrefresh_button.on_click(refresh_status)\n\ndisplay(refresh_button)\ndisplay(status_output)\nrefresh_status()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìÑ Document Management\n",
    "\n",
    "Upload PDF documents to the system for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# File upload interface\nupload_output = widgets.Output()\n\nfile_upload = widgets.FileUpload(\n    accept='.pdf',\n    multiple=True,\n    description='Upload PDFs'\n)\n\ndef handle_upload(change):\n    with upload_output:\n        clear_output()\n        uploaded_files = change['new']\n        \n        if not uploaded_files:\n            return\n        \n        display(HTML(f'<p>üì§ Uploading {len(uploaded_files)} file(s)...</p>'))\n        \n        for file_info in uploaded_files:\n            filename = file_info['name']\n            content = file_info['content']\n            filepath = config.PDF_DIR / filename\n            \n            with open(filepath, 'wb') as f:\n                f.write(content)\n            \n            display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Uploaded: {filename}</p>'))\n        \n        display(HTML('<p style=\"font-weight: bold; margin-top: 15px;\">Upload complete! Now run \"Process Documents\" below.</p>'))\n        refresh_status()\n\nfile_upload.observe(handle_upload, names='value')\n\ndisplay(file_upload)\ndisplay(upload_output)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## ‚öôÔ∏è Processing Pipeline\n\nProcess documents through the complete RAG pipeline:\n\n**Local Mode:** extraction ‚Üí chunking ‚Üí header generation ‚Üí embedding ‚Üí FAISS indexing ‚Üí local cache\n\n**Azure Mode:** extraction ‚Üí chunking ‚Üí header generation ‚Üí Cosmos DB storage ‚Üí embedding generation ‚Üí Azure AI Search indexing\n\nClick the button below to see step-by-step execution with educational explanations!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Processing controls\nprocess_output = widgets.Output()\n\nprocess_button = widgets.Button(\n    description='üöÄ Process Documents',\n    button_style='success',\n    icon='cogs',\n    layout=widgets.Layout(width='200px', height='45px', margin='10px 0')\n)\n\nrebuild_button = widgets.Button(\n    description='üî® Rebuild Index',\n    button_style='warning',\n    icon='refresh',\n    layout=widgets.Layout(width='200px', height='45px', margin='10px 0')\n)\n\ndef process_documents_azure(process_output):\n    \"\"\"Azure mode: Process documents and populate Cosmos DB + Azure AI Search.\"\"\"\n    from rag import azure_cosmos, azure_search\n    from rag.embeddings import get_embeddings_batch\n    import numpy as np\n    import time\n    \n    display(HTML('<h3>‚òÅÔ∏è Starting Azure Processing Pipeline...</h3>'))\n    display(HTML('<p style=\"color: #666; font-style: italic;\">This will teach you how production RAG systems work in the cloud!</p>'))\n    \n    try:\n        # Step 1: Load documents from both JSON and PDFs\n        display(HTML('''\n        <div style=\"background-color: #e7f3ff; padding: 15px; border-left: 4px solid #0066cc; margin: 15px 0;\">\n            <h4 style=\"margin-top: 0;\">üìñ Step 1/7: Loading Documents</h4>\n            <p><strong>Learning:</strong> Documents can come from multiple sources (JSON files, PDFs, APIs, etc.)</p>\n        </div>\n        '''))\n        \n        from rag.ingestion import extract_text_from_pdfs, load_json_documents\n        \n        # Load JSON documents (web-scraped)\n        json_docs = load_json_documents(config.DATA_DIR)\n        display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Loaded {len(json_docs)} JSON documents</p>'))\n        \n        # Extract PDF documents\n        pdf_docs = extract_text_from_pdfs(config.PDF_DIR)\n        display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Extracted {len(pdf_docs)} PDF documents</p>'))\n        \n        # Combine all documents\n        documents = json_docs + pdf_docs\n        display(HTML(f'<p style=\"color: #0066cc; font-weight: bold;\">üìö Total: {len(documents)} documents loaded into memory</p>'))\n        \n        # Step 2: Save documents to Cosmos DB\n        display(HTML('''\n        <div style=\"background-color: #e7f3ff; padding: 15px; border-left: 4px solid #0066cc; margin: 15px 0;\">\n            <h4 style=\"margin-top: 0;\">‚òÅÔ∏è Step 2/7: Storing Documents in Cosmos DB</h4>\n            <p><strong>Learning:</strong> Azure Cosmos DB is a globally distributed NoSQL database. It stores your documents with automatic indexing, low-latency access, and built-in replication.</p>\n            <p><strong>Why this matters:</strong> Unlike local files, Cosmos DB provides enterprise-grade durability, scalability, and multi-region support.</p>\n        </div>\n        '''))\n        \n        azure_cosmos.save_documents(documents)\n        display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Saved {len(documents)} documents to Cosmos DB container: <code>{config.COSMOS_CONTAINER_DOCUMENTS}</code></p>'))\n        \n        # Step 3: Chunk documents\n        display(HTML('''\n        <div style=\"background-color: #e7f3ff; padding: 15px; border-left: 4px solid #0066cc; margin: 15px 0;\">\n            <h4 style=\"margin-top: 0;\">‚úÇÔ∏è Step 3/7: Semantic Chunking</h4>\n            <p><strong>Learning:</strong> Documents are too long to embed as single units. We split them into smaller \"chunks\" at semantic boundaries (paragraphs, sections) for better retrieval granularity.</p>\n            <p><strong>Why this matters:</strong> Smaller chunks = more precise retrieval. A query about \"diabetes symptoms\" will match the specific paragraph, not the entire 50-page document.</p>\n        </div>\n        '''))\n        \n        from rag.chunking import SemanticChunker\n        chunker = SemanticChunker(max_words=config.SEMANTIC_MAX_WORDS)\n        chunks = chunker.chunk_documents(documents)\n        display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Created {len(chunks)} semantic chunks (max {config.SEMANTIC_MAX_WORDS} words each)</p>'))\n        \n        # Step 4: Generate contextual headers\n        display(HTML('''\n        <div style=\"background-color: #e7f3ff; padding: 15px; border-left: 4px solid #0066cc; margin: 15px 0;\">\n            <h4 style=\"margin-top: 0;\">üè∑Ô∏è Step 4/7: Contextual Header Generation</h4>\n            <p><strong>Learning:</strong> Each chunk gets a \"contextual header\" that describes its hierarchical position in the document (e.g., \"NIH Guidelines ‚Üí Diabetes ‚Üí Type 2 ‚Üí Treatment Options\").</p>\n            <p><strong>Why this matters:</strong> This is the secret sauce! Headers provide context that dramatically improves embedding quality and retrieval accuracy. A chunk about \"insulin dosing\" is more meaningful when you know it's from a diabetes treatment protocol.</p>\n            <p><strong>How it works:</strong> We use Azure OpenAI's GPT model to analyze document structure and generate these headers automatically.</p>\n        </div>\n        '''))\n        \n        from rag.headers import ContextualHeaderGenerator\n        header_gen = ContextualHeaderGenerator()\n        chunks = header_gen.generate_headers_batch(chunks, batch_size=config.BATCH_SIZE)\n        display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Generated contextual headers for {len(chunks)} chunks using Azure OpenAI</p>'))\n        \n        # Step 5: Save chunks to Cosmos DB\n        display(HTML('''\n        <div style=\"background-color: #e7f3ff; padding: 15px; border-left: 4px solid #0066cc; margin: 15px 0;\">\n            <h4 style=\"margin-top: 0;\">‚òÅÔ∏è Step 5/7: Storing Chunks in Cosmos DB</h4>\n            <p><strong>Learning:</strong> Now we store the processed chunks (with headers) in a separate Cosmos DB container.</p>\n            <p><strong>Why separate containers:</strong> Documents and chunks have different access patterns. This separation allows us to query chunks efficiently without loading entire documents.</p>\n        </div>\n        '''))\n        \n        azure_cosmos.save_chunks(chunks)\n        display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Saved {len(chunks)} chunks to Cosmos DB container: <code>{config.COSMOS_CONTAINER_CHUNKS}</code></p>'))\n        \n        # Step 6: Generate embeddings\n        display(HTML('''\n        <div style=\"background-color: #e7f3ff; padding: 15px; border-left: 4px solid #0066cc; margin: 15px 0;\">\n            <h4 style=\"margin-top: 0;\">üßÆ Step 6/7: Generating Vector Embeddings</h4>\n            <p><strong>Learning:</strong> Embeddings are numerical vector representations of text. Azure OpenAI's <code>text-embedding-3-large</code> model converts each chunk (with header) into a 3072-dimensional vector.</p>\n            <p><strong>Why this matters:</strong> Vectors enable semantic similarity search. \"What are symptoms of diabetes?\" will match chunks about \"signs of high blood sugar\" even though they use different words!</p>\n            <p><strong>Rate limiting:</strong> We batch requests ({config.EMBED_BATCH_SIZE} at a time) with delays to respect API limits.</p>\n        </div>\n        '''))\n        \n        texts = [c.augmented_chunk for c in chunks]\n        embeddings_list = []\n        batch_size = config.EMBED_BATCH_SIZE\n        total_batches = (len(texts) + batch_size - 1) // batch_size\n        \n        for i in range(0, len(texts), batch_size):\n            batch = texts[i:i + batch_size]\n            batch_num = i // batch_size + 1\n            \n            batch_emb = get_embeddings_batch(batch)\n            embeddings_list.extend(batch_emb)\n            \n            display(HTML(f'<p>üìä Batch {batch_num}/{total_batches} complete ({len(batch)} embeddings)</p>'))\n            \n            if batch_num < total_batches:\n                time.sleep(config.EMBED_DELAY_SECONDS)\n        \n        embeddings = np.asarray(embeddings_list, dtype=np.float32)\n        display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Generated {embeddings.shape[0]:,} embeddings with {embeddings.shape[1]:,} dimensions each</p>'))\n        \n        # Step 7: Create Azure AI Search index and upload\n        display(HTML('''\n        <div style=\"background-color: #e7f3ff; padding: 15px; border-left: 4px solid #0066cc; margin: 15px 0;\">\n            <h4 style=\"margin-top: 0;\">üîç Step 7/7: Populating Azure AI Search Index</h4>\n            <p><strong>Learning:</strong> Azure AI Search is a managed vector database that uses the HNSW (Hierarchical Navigable Small World) algorithm for approximate nearest neighbor search.</p>\n            <p><strong>How HNSW works:</strong> It builds a multi-layer graph where each layer has progressively fewer nodes. Search starts at the top (sparse) layer and zooms down to find nearest neighbors efficiently.</p>\n            <p><strong>Why Azure Search:</strong> Handles billions of vectors, sub-second queries, automatic scaling, and enterprise security.</p>\n            <p><strong>What we're indexing:</strong> Each chunk's embedding (3072-D vector) along with metadata (title, source, header, etc.)</p>\n        </div>\n        '''))\n        \n        # Create index if needed\n        azure_search.create_search_index(embedding_dimensions=3072)\n        display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Created/verified Azure Search index: <code>{config.AZURE_SEARCH_INDEX_NAME}</code></p>'))\n        \n        # Upload chunks with embeddings\n        azure_search.upload_chunks(chunks, embeddings, batch_size=100)\n        search_count = azure_search.get_document_count()\n        display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Uploaded {search_count:,} documents to Azure AI Search</p>'))\n        \n        # Success message\n        display(HTML(f'''\n            <div style=\"background-color: #d4edda; border: 1px solid #c3e6cb; color: #155724; padding: 20px; border-radius: 10px; margin-top: 20px;\">\n                <h3 style=\"margin-top: 0;\">üéâ Azure Processing Complete!</h3>\n                <p><strong>What you just learned:</strong></p>\n                <ul>\n                    <li>‚úÖ How to store documents in Cosmos DB (globally distributed NoSQL)</li>\n                    <li>‚úÖ How semantic chunking improves retrieval granularity</li>\n                    <li>‚úÖ How contextual headers enhance embedding quality</li>\n                    <li>‚úÖ How Azure OpenAI generates vector embeddings</li>\n                    <li>‚úÖ How Azure AI Search indexes vectors with HNSW algorithm</li>\n                </ul>\n                <p><strong>Your production RAG system is now live!</strong></p>\n                <ul style=\"margin-bottom: 0;\">\n                    <li>üìÑ Documents in Cosmos DB: {len(documents):,}</li>\n                    <li>‚úÇÔ∏è Chunks created: {len(chunks):,}</li>\n                    <li>üßÆ Embeddings generated: {embeddings.shape[0]:,} √ó {embeddings.shape[1]:,}D</li>\n                    <li>üîç Vectors in Azure Search: {search_count:,}</li>\n                </ul>\n            </div>\n        '''))\n        \n        refresh_status()\n        \n    except Exception as e:\n        display(HTML(f'<p style=\"color: #dc3545; font-weight: bold;\">‚ùå Error: {str(e)}</p>'))\n        import traceback\n        display(HTML(f'<pre style=\"background-color: #f8f9fa; padding: 10px; border-radius: 5px; font-size: 11px;\">{traceback.format_exc()}</pre>'))\n\ndef process_documents_local(process_output):\n    \"\"\"Local mode: Process documents and build FAISS index.\"\"\"\n    from rag.cache import save_chunks, save_faiss_index, save_metadata\n    \n    display(HTML('<h3>üìö Starting Local Processing Pipeline...</h3>'))\n    display(HTML('<p style=\"color: #666; font-style: italic;\">This will teach you how RAG systems work from the ground up!</p>'))\n    \n    try:\n        # Step 1: Load documents from both JSON and PDFs\n        display(HTML('''\n        <div style=\"background-color: #f0f9ff; padding: 15px; border-left: 4px solid #0066cc; margin: 15px 0;\">\n            <h4 style=\"margin-top: 0;\">üìñ Step 1/6: Loading Documents</h4>\n            <p><strong>Learning:</strong> Documents can come from multiple sources (JSON files, PDFs, APIs, etc.)</p>\n        </div>\n        '''))\n        \n        from rag.ingestion import extract_text_from_pdfs, load_json_documents\n        \n        # Load JSON documents (web-scraped)\n        json_docs = load_json_documents(config.DATA_DIR)\n        display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Loaded {len(json_docs)} JSON documents</p>'))\n        \n        # Extract PDF documents\n        pdf_docs = extract_text_from_pdfs(config.PDF_DIR)\n        display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Extracted {len(pdf_docs)} PDF documents</p>'))\n        \n        # Combine all documents\n        documents = json_docs + pdf_docs\n        display(HTML(f'<p style=\"color: #0066cc; font-weight: bold;\">üìö Total: {len(documents)} documents</p>'))\n        \n        # Step 2: Chunk documents\n        display(HTML('''\n        <div style=\"background-color: #f0f9ff; padding: 15px; border-left: 4px solid #0066cc; margin: 15px 0;\">\n            <h4 style=\"margin-top: 0;\">‚úÇÔ∏è Step 2/6: Semantic Chunking</h4>\n            <p><strong>Learning:</strong> We split documents into smaller chunks at semantic boundaries for better retrieval precision.</p>\n            <p><strong>Why:</strong> Smaller chunks mean more accurate matches. A query about \"symptoms\" will retrieve just that section, not the entire document.</p>\n        </div>\n        '''))\n        \n        from rag.chunking import SemanticChunker\n        chunker = SemanticChunker(max_words=config.SEMANTIC_MAX_WORDS)\n        chunks = chunker.chunk_documents(documents)\n        display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Created {len(chunks)} chunks</p>'))\n        \n        # Step 3: Generate contextual headers\n        display(HTML('''\n        <div style=\"background-color: #f0f9ff; padding: 15px; border-left: 4px solid #0066cc; margin: 15px 0;\">\n            <h4 style=\"margin-top: 0;\">üè∑Ô∏è Step 3/6: Contextual Headers</h4>\n            <p><strong>Learning:</strong> We add contextual headers (e.g., \"NIH ‚Üí Diabetes ‚Üí Treatment\") to each chunk before embedding.</p>\n            <p><strong>Why:</strong> Context improves embedding quality. \"Insulin dosing\" means more when you know it's from a diabetes treatment guide.</p>\n        </div>\n        '''))\n        \n        from rag.headers import ContextualHeaderGenerator\n        header_gen = ContextualHeaderGenerator()\n        chunks = header_gen.generate_headers_batch(chunks, batch_size=config.BATCH_SIZE)\n        display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Generated headers for all chunks</p>'))\n        \n        # Step 4: Generate embeddings with batching\n        display(HTML('''\n        <div style=\"background-color: #f0f9ff; padding: 15px; border-left: 4px solid #0066cc; margin: 15px 0;\">\n            <h4 style=\"margin-top: 0;\">üßÆ Step 4/6: Vector Embeddings</h4>\n            <p><strong>Learning:</strong> Azure OpenAI converts text into 3072-dimensional vectors that capture semantic meaning.</p>\n            <p><strong>How:</strong> Similar concepts have similar vectors. \"diabetes\" and \"high blood sugar\" will be close in vector space.</p>\n        </div>\n        '''))\n        \n        from rag.embeddings import get_embeddings_batch\n        from rag.cache import save_embeddings\n        import time\n        \n        texts_to_embed = [f\"{chunk.ctx_header}\\n\\n{chunk.raw_chunk}\" for chunk in chunks]\n        embeddings = []\n        batch_size = config.EMBED_BATCH_SIZE\n        total_batches = (len(texts_to_embed) + batch_size - 1) // batch_size\n        \n        for i in range(0, len(texts_to_embed), batch_size):\n            batch = texts_to_embed[i:i + batch_size]\n            batch_embeddings = get_embeddings_batch(batch)\n            \n            # Check for zero vectors (failed embeddings)\n            if batch_embeddings and any(sum(emb) == 0 for emb in batch_embeddings):\n                raise RuntimeError(f\"Embedding generation failed for batch {i//batch_size + 1} (returned zero vectors)\")\n            \n            embeddings.extend(batch_embeddings)\n            batch_num = i // batch_size + 1\n            display(HTML(f'<p>üìä Completed batch {batch_num}/{total_batches}</p>'))\n            \n            # Delay between batches (except last)\n            if batch_num < total_batches:\n                time.sleep(config.EMBED_DELAY_SECONDS)\n        \n        display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Generated {len(embeddings)} embeddings</p>'))\n        \n        # Step 5: Build FAISS index\n        display(HTML('''\n        <div style=\"background-color: #f0f9ff; padding: 15px; border-left: 4px solid #0066cc; margin: 15px 0;\">\n            <h4 style=\"margin-top: 0;\">üîç Step 5/6: FAISS Index</h4>\n            <p><strong>Learning:</strong> FAISS (Facebook AI Similarity Search) builds an index for fast nearest-neighbor search.</p>\n            <p><strong>Algorithm:</strong> We use IndexFlatIP (Inner Product) with normalized vectors for cosine similarity.</p>\n            <p><strong>How it works:</strong> When you search, FAISS compares your query vector against all stored vectors and returns the closest matches.</p>\n        </div>\n        '''))\n        \n        import numpy as np\n        import faiss\n        embeddings_array = np.array(embeddings).astype('float32')\n        dimension = embeddings_array.shape[1]\n        index = faiss.IndexFlatIP(dimension)  # Inner product for cosine similarity\n        faiss.normalize_L2(embeddings_array)  # Normalize for cosine similarity\n        index.add(embeddings_array)\n        display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Built FAISS index with {index.ntotal} vectors ({dimension} dimensions)</p>'))\n        \n        # Step 6: Save everything to cache\n        display(HTML('''\n        <div style=\"background-color: #f0f9ff; padding: 15px; border-left: 4px solid #0066cc; margin: 15px 0;\">\n            <h4 style=\"margin-top: 0;\">üíæ Step 6/6: Save to Local Cache</h4>\n            <p><strong>Learning:</strong> We save chunks (Python pickle), index (binary), and metadata (JSON) to disk.</p>\n            <p><strong>Why cache:</strong> Rebuilding takes time. Caching lets us reload instantly for demos and queries.</p>\n        </div>\n        '''))\n        \n        save_chunks(chunks)\n        save_faiss_index(index)\n        \n        # Build metadata for retrieval\n        chunk_records = []\n        for i, chunk in enumerate(chunks):\n            chunk_records.append({\n                'chunk_id': chunk.chunk_id,\n                'doc_title': chunk.doc_title,\n                'source_url': chunk.source_url,\n                'ctx_header': chunk.ctx_header,\n                'chunk_index': chunk.chunk_index\n            })\n        save_metadata(chunk_records)\n        \n        display(HTML('<p style=\"color: #28a745;\">‚úÖ Saved to cache</p>'))\n        \n        # Success message\n        display(HTML(f'''\n            <div style=\"background-color: #d4edda; border: 1px solid #c3e6cb; color: #155724; padding: 20px; border-radius: 10px; margin-top: 20px;\">\n                <h3 style=\"margin-top: 0;\">üéâ Local Processing Complete!</h3>\n                <p><strong>What you just learned:</strong></p>\n                <ul>\n                    <li>‚úÖ How to chunk documents semantically</li>\n                    <li>‚úÖ How contextual headers improve retrieval</li>\n                    <li>‚úÖ How Azure OpenAI generates embeddings</li>\n                    <li>‚úÖ How FAISS indexes vectors for fast search</li>\n                    <li>‚úÖ How to cache data for quick reloading</li>\n                </ul>\n                <p><strong>Your local RAG system is ready!</strong></p>\n                <ul style=\"margin-bottom: 0;\">\n                    <li>JSON documents: {len(json_docs)}</li>\n                    <li>PDF documents: {len(pdf_docs)}</li>\n                    <li>Total documents processed: {len(documents)}</li>\n                    <li>Chunks created: {len(chunks)}</li>\n                    <li>Embeddings generated: {len(embeddings)}</li>\n                    <li>Index built: {index.ntotal} vectors</li>\n                </ul>\n            </div>\n        '''))\n        \n        refresh_status()\n        \n    except Exception as e:\n        display(HTML(f'<p style=\"color: #dc3545; font-weight: bold;\">‚ùå Error: {str(e)}</p>'))\n        import traceback\n        display(HTML(f'<pre style=\"background-color: #f8f9fa; padding: 10px; border-radius: 5px; font-size: 11px;\">{traceback.format_exc()}</pre>'))\n\ndef process_documents(button):\n    \"\"\"Route to appropriate processing function based on storage mode.\"\"\"\n    with process_output:\n        clear_output(wait=True)\n        \n        if config.STORAGE_MODE == \"azure\":\n            process_documents_azure(process_output)\n        else:\n            process_documents_local(process_output)\n\ndef rebuild_index(button):\n    \"\"\"Rebuild index from existing chunks.\"\"\"\n    with process_output:\n        clear_output(wait=True)\n        \n        if config.STORAGE_MODE == \"azure\":\n            # Azure rebuild: regenerate embeddings and re-upload to Azure Search\n            display(HTML('<h3>üî® Rebuilding Azure AI Search Index...</h3>'))\n            \n            try:\n                from rag import azure_cosmos, azure_search\n                from rag.embeddings import get_embeddings_batch\n                import numpy as np\n                import time\n                \n                # Load existing chunks from Cosmos DB\n                chunks = azure_cosmos.load_chunks()\n                if not chunks:\n                    display(HTML('<p style=\"color: #dc3545;\">‚ùå No chunks found in Cosmos DB. Please process documents first.</p>'))\n                    return\n                \n                display(HTML(f'<p>üì¶ Loaded {len(chunks)} chunks from Cosmos DB</p>'))\n                \n                # Regenerate embeddings\n                display(HTML('<p>üßÆ Regenerating embeddings...</p>'))\n                texts = [c.augmented_chunk for c in chunks]\n                embeddings_list = []\n                batch_size = config.EMBED_BATCH_SIZE\n                total_batches = (len(texts) + batch_size - 1) // batch_size\n                \n                for i in range(0, len(texts), batch_size):\n                    batch = texts[i:i + batch_size]\n                    batch_num = i // batch_size + 1\n                    \n                    batch_emb = get_embeddings_batch(batch)\n                    embeddings_list.extend(batch_emb)\n                    display(HTML(f'<p>üìä Batch {batch_num}/{total_batches} complete</p>'))\n                    \n                    if batch_num < total_batches:\n                        time.sleep(config.EMBED_DELAY_SECONDS)\n                \n                embeddings = np.asarray(embeddings_list, dtype=np.float32)\n                display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Generated {embeddings.shape[0]:,} embeddings</p>'))\n                \n                # Recreate index and upload\n                azure_search.create_search_index(embedding_dimensions=3072, force_recreate=True)\n                azure_search.upload_chunks(chunks, embeddings, batch_size=100)\n                search_count = azure_search.get_document_count()\n                \n                display(HTML(f'''\n                    <div style=\"background-color: #d4edda; border: 1px solid #c3e6cb; color: #155724; padding: 20px; border-radius: 10px; margin-top: 20px;\">\n                        <h3 style=\"margin-top: 0;\">‚úÖ Azure Index Rebuilt!</h3>\n                        <p style=\"margin-bottom: 0;\">Azure AI Search updated with {search_count:,} vectors.</p>\n                    </div>\n                '''))\n                \n                refresh_status()\n                \n            except Exception as e:\n                display(HTML(f'<p style=\"color: #dc3545; font-weight: bold;\">‚ùå Error: {str(e)}</p>'))\n                import traceback\n                display(HTML(f'<pre style=\"background-color: #f8f9fa; padding: 10px; border-radius: 5px; font-size: 11px;\">{traceback.format_exc()}</pre>'))\n        \n        else:\n            # Local rebuild: same as before\n            display(HTML('<h3>üî® Rebuilding FAISS Index...</h3>'))\n            \n            try:\n                from rag.cache import load_chunks, save_faiss_index\n                from rag.embeddings import get_embeddings_batch\n                import numpy as np\n                import faiss\n                import time\n                \n                # Load existing chunks\n                chunks = load_chunks()\n                if not chunks:\n                    display(HTML('<p style=\"color: #dc3545;\">‚ùå No chunks found. Please process documents first.</p>'))\n                    return\n                \n                display(HTML(f'<p>üì¶ Loaded {len(chunks)} existing chunks</p>'))\n                \n                # Regenerate embeddings with batching\n                display(HTML('<p>üßÆ Regenerating embeddings...</p>'))\n                \n                texts_to_embed = [f\"{chunk.ctx_header}\\n\\n{chunk.raw_chunk}\" for chunk in chunks]\n                embeddings = []\n                batch_size = config.EMBED_BATCH_SIZE\n                total_batches = (len(texts_to_embed) + batch_size - 1) // batch_size\n                \n                for i in range(0, len(texts_to_embed), batch_size):\n                    batch = texts_to_embed[i:i + batch_size]\n                    batch_embeddings = get_embeddings_batch(batch)\n                    \n                    # Check for zero vectors (failed embeddings)\n                    if batch_embeddings and any(sum(emb) == 0 for emb in batch_embeddings):\n                        raise RuntimeError(f\"Embedding generation failed for batch {i//batch_size + 1} (returned zero vectors)\")\n                    \n                    embeddings.extend(batch_embeddings)\n                    batch_num = i // batch_size + 1\n                    display(HTML(f'<p>üìä Completed batch {batch_num}/{total_batches}</p>'))\n                    \n                    # Delay between batches (except last)\n                    if batch_num < total_batches:\n                        time.sleep(config.EMBED_DELAY_SECONDS)\n                \n                display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Generated {len(embeddings)} embeddings</p>'))\n                \n                # Rebuild index\n                display(HTML('<p>üîç Building new FAISS index...</p>'))\n                embeddings_array = np.array(embeddings).astype('float32')\n                dimension = embeddings_array.shape[1]\n                index = faiss.IndexFlatIP(dimension)\n                faiss.normalize_L2(embeddings_array)\n                index.add(embeddings_array)\n                \n                # Save\n                save_faiss_index(index)\n                \n                display(HTML(f'''\n                    <div style=\"background-color: #d4edda; border: 1px solid #c3e6cb; color: #155724; padding: 20px; border-radius: 10px; margin-top: 20px;\">\n                        <h3 style=\"margin-top: 0;\">‚úÖ Index Rebuilt Successfully!</h3>\n                        <p style=\"margin-bottom: 0;\">FAISS index updated with {index.ntotal} vectors.</p>\n                    </div>\n                '''))\n                \n                refresh_status()\n                \n            except Exception as e:\n                display(HTML(f'<p style=\"color: #dc3545; font-weight: bold;\">‚ùå Error: {str(e)}</p>'))\n                import traceback\n                display(HTML(f'<pre style=\"background-color: #f8f9fa; padding: 10px; border-radius: 5px; font-size: 11px;\">{traceback.format_exc()}</pre>'))\n\nprocess_button.on_click(process_documents)\nrebuild_button.on_click(rebuild_index)\n\ndisplay(widgets.HBox([process_button, rebuild_button]))\ndisplay(process_output)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## üóëÔ∏è Data Management\n\n**Local Mode:** Clear local cache files\n\n**Azure Mode:** Delete data from Cosmos DB and Azure AI Search"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Data management\ncache_output = widgets.Output()\n\nclear_cache_button = widgets.Button(\n    description='üóëÔ∏è Clear All Data',\n    button_style='danger',\n    layout=widgets.Layout(width='200px', margin='10px 0')\n)\n\ndef clear_cache(button):\n    with cache_output:\n        clear_output()\n        \n        if config.STORAGE_MODE == \"azure\":\n            # Azure mode: delete from Cosmos DB and Azure Search\n            display(HTML('<p style=\"color: #dc3545; font-weight: bold;\">‚ö†Ô∏è WARNING: This will delete all data from Azure services!</p>'))\n            display(HTML('<p>Clearing Azure data...</p>'))\n            \n            try:\n                from rag import azure_cosmos, azure_search\n                \n                # Delete from Cosmos DB\n                display(HTML('<p>üóëÔ∏è Deleting documents from Cosmos DB...</p>'))\n                azure_cosmos.delete_all_documents()\n                display(HTML('<p style=\"color: #28a745;\">‚úÖ Documents deleted</p>'))\n                \n                display(HTML('<p>üóëÔ∏è Deleting chunks from Cosmos DB...</p>'))\n                azure_cosmos.delete_all_chunks()\n                display(HTML('<p style=\"color: #28a745;\">‚úÖ Chunks deleted</p>'))\n                \n                # Delete Azure Search index\n                display(HTML('<p>üóëÔ∏è Deleting Azure AI Search index...</p>'))\n                from azure.search.documents.indexes import SearchIndexClient\n                from azure.core.credentials import AzureKeyCredential\n                \n                index_client = SearchIndexClient(\n                    endpoint=config.AZURE_SEARCH_ENDPOINT,\n                    credential=AzureKeyCredential(config.AZURE_SEARCH_KEY)\n                )\n                \n                try:\n                    index_client.delete_index(config.AZURE_SEARCH_INDEX_NAME)\n                    display(HTML('<p style=\"color: #28a745;\">‚úÖ Azure Search index deleted</p>'))\n                except Exception:\n                    display(HTML('<p style=\"color: #ffc107;\">‚ö†Ô∏è Index not found or already deleted</p>'))\n                \n                display(HTML('<p style=\"font-weight: bold; margin-top: 15px; color: #28a745;\">‚úÖ All Azure data cleared. Run \"Process Documents\" to rebuild.</p>'))\n                refresh_status()\n                \n            except Exception as e:\n                display(HTML(f'<p style=\"color: #dc3545;\">‚ùå Error: {str(e)}</p>'))\n        \n        else:\n            # Local mode: clear cache files\n            display(HTML('<p>‚ö†Ô∏è Clearing local cache files...</p>'))\n            \n            cache_files = [\n                config.CACHE_DIR / 'chunks.pkl',\n                config.CACHE_DIR / 'faiss_index.bin',\n                config.CACHE_DIR / 'chunk_metadata.json'\n            ]\n            \n            for filepath in cache_files:\n                if filepath.exists():\n                    filepath.unlink()\n                    display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Deleted: {filepath.name}</p>'))\n            \n            display(HTML('<p style=\"font-weight: bold; margin-top: 15px;\">Cache cleared. Run \"Process Documents\" to rebuild.</p>'))\n            refresh_status()\n\nclear_cache_button.on_click(clear_cache)\n\ndisplay(clear_cache_button)\ndisplay(cache_output)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìà System Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Display system configuration\nif config.STORAGE_MODE == \"azure\":\n    info_html = f'''\n<div style=\"background-color: #f0fff4; padding: 20px; border-radius: 10px; border: 1px solid #28a745;\">\n    <h3 style=\"margin-top: 0; color: #28a745;\">‚öôÔ∏è Azure Mode Configuration</h3>\n    <table style=\"width: 100%; border-collapse: collapse;\">\n        <tr style=\"border-bottom: 1px solid #dee2e6;\">\n            <td style=\"padding: 8px; font-weight: bold;\">Storage Mode:</td>\n            <td style=\"padding: 8px;\"><code>azure</code></td>\n        </tr>\n        <tr style=\"border-bottom: 1px solid #dee2e6;\">\n            <td style=\"padding: 8px; font-weight: bold;\">Azure OpenAI Endpoint:</td>\n            <td style=\"padding: 8px;\"><code>{config.AZURE_OPENAI_ENDPOINT[:50]}...</code></td>\n        </tr>\n        <tr style=\"border-bottom: 1px solid #dee2e6;\">\n            <td style=\"padding: 8px; font-weight: bold;\">Cosmos DB:</td>\n            <td style=\"padding: 8px;\"><code>{config.COSMOS_DB_NAME}</code></td>\n        </tr>\n        <tr style=\"border-bottom: 1px solid #dee2e6;\">\n            <td style=\"padding: 8px; font-weight: bold;\">Cosmos Containers:</td>\n            <td style=\"padding: 8px;\"><code>{config.COSMOS_CONTAINER_DOCUMENTS}</code>, <code>{config.COSMOS_CONTAINER_CHUNKS}</code></td>\n        </tr>\n        <tr style=\"border-bottom: 1px solid #dee2e6;\">\n            <td style=\"padding: 8px; font-weight: bold;\">Azure Search Index:</td>\n            <td style=\"padding: 8px;\"><code>{config.AZURE_SEARCH_INDEX_NAME}</code></td>\n        </tr>\n        <tr style=\"border-bottom: 1px solid #dee2e6;\">\n            <td style=\"padding: 8px; font-weight: bold;\">Embedding Model:</td>\n            <td style=\"padding: 8px;\"><code>{config.AOAI_EMBED_MODEL}</code> (3072 dimensions)</td>\n        </tr>\n        <tr style=\"border-bottom: 1px solid #dee2e6;\">\n            <td style=\"padding: 8px; font-weight: bold;\">Chat Model:</td>\n            <td style=\"padding: 8px;\"><code>{config.AOAI_CHAT_MODEL}</code></td>\n        </tr>\n        <tr style=\"border-bottom: 1px solid #dee2e6;\">\n            <td style=\"padding: 8px; font-weight: bold;\">Max Chunk Words:</td>\n            <td style=\"padding: 8px;\">{config.SEMANTIC_MAX_WORDS}</td>\n        </tr>\n        <tr style=\"border-bottom: 1px solid #dee2e6;\">\n            <td style=\"padding: 8px; font-weight: bold;\">Embedding Batch Size:</td>\n            <td style=\"padding: 8px;\">{config.EMBED_BATCH_SIZE}</td>\n        </tr>\n        <tr>\n            <td style=\"padding: 8px; font-weight: bold;\">Vector Search Algorithm:</td>\n            <td style=\"padding: 8px;\">HNSW (Hierarchical Navigable Small World)</td>\n        </tr>\n    </table>\n    <p style=\"margin-top: 15px; color: #666; font-size: 14px;\">\n        <strong>üìö Learning:</strong> This configuration shows your production Azure infrastructure. \n        Data is stored in globally distributed services with automatic scaling and enterprise security.\n    </p>\n</div>\n'''\nelse:\n    info_html = f'''\n<div style=\"background-color: #f8f9fa; padding: 20px; border-radius: 10px; border: 1px solid #dee2e6;\">\n    <h3 style=\"margin-top: 0; color: #495057;\">‚öôÔ∏è Local Mode Configuration</h3>\n    <table style=\"width: 100%; border-collapse: collapse;\">\n        <tr style=\"border-bottom: 1px solid #dee2e6;\">\n            <td style=\"padding: 8px; font-weight: bold;\">Storage Mode:</td>\n            <td style=\"padding: 8px;\"><code>local</code></td>\n        </tr>\n        <tr style=\"border-bottom: 1px solid #dee2e6;\">\n            <td style=\"padding: 8px; font-weight: bold;\">Data Directory:</td>\n            <td style=\"padding: 8px;\"><code>{config.DATA_DIR}</code></td>\n        </tr>\n        <tr style=\"border-bottom: 1px solid #dee2e6;\">\n            <td style=\"padding: 8px; font-weight: bold;\">PDF Directory:</td>\n            <td style=\"padding: 8px;\"><code>{config.PDF_DIR}</code></td>\n        </tr>\n        <tr style=\"border-bottom: 1px solid #dee2e6;\">\n            <td style=\"padding: 8px; font-weight: bold;\">Cache Directory:</td>\n            <td style=\"padding: 8px;\"><code>{config.CACHE_DIR}</code></td>\n        </tr>\n        <tr style=\"border-bottom: 1px solid #dee2e6;\">\n            <td style=\"padding: 8px; font-weight: bold;\">Embedding Model:</td>\n            <td style=\"padding: 8px;\"><code>{config.AOAI_EMBED_MODEL}</code> (3072 dimensions)</td>\n        </tr>\n        <tr style=\"border-bottom: 1px solid #dee2e6;\">\n            <td style=\"padding: 8px; font-weight: bold;\">Chat Model:</td>\n            <td style=\"padding: 8px;\"><code>{config.AOAI_CHAT_MODEL}</code></td>\n        </tr>\n        <tr style=\"border-bottom: 1px solid #dee2e6;\">\n            <td style=\"padding: 8px; font-weight: bold;\">Max Chunk Words:</td>\n            <td style=\"padding: 8px;\">{config.SEMANTIC_MAX_WORDS}</td>\n        </tr>\n        <tr style=\"border-bottom: 1px solid #dee2e6;\">\n            <td style=\"padding: 8px; font-weight: bold;\">Embedding Batch Size:</td>\n            <td style=\"padding: 8px;\">{config.EMBED_BATCH_SIZE}</td>\n        </tr>\n        <tr>\n            <td style=\"padding: 8px; font-weight: bold;\">Vector Search Algorithm:</td>\n            <td style=\"padding: 8px;\">FAISS IndexFlatIP (exact cosine similarity)</td>\n        </tr>\n    </table>\n    <p style=\"margin-top: 15px; color: #666; font-size: 14px;\">\n        <strong>üìö Learning:</strong> This configuration shows your local development setup. \n        All data is stored on your machine for learning and experimentation.\n    </p>\n</div>\n'''\n\ndisplay(HTML(info_html))"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}